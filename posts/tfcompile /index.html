<!DOCTYPE html>
<html prefix="" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Example of how to use XLA AOT via tfcompile to build a Keras model into a shared library.">
<meta name="viewport" content="width=device-width">
<title>tfcompile | Carl Thomé</title>
<link href="../../assets/css/rst.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/code.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/theme.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="../../assets/css/screen.css">
<link rel="stylesheet" type="text/css" href="../../assets/css/nav.css">
<link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic%7COpen+Sans:700,400%7CInconsolata">
<link href="../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#393069">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../rss.xml">
<link rel="canonical" href="https://carlthome.github.io/posts/tfcompile%20/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Carl Thomé">
<link rel="prev" href="../online-cqt%20/" title="Online CQT" type="text/html">
<link rel="next" href="../reading-audio-files-and-computing-spectrograms-with-tf.data%20/" title="Reading audio files and computing spectrograms with tf.data" type="text/html">
<meta property="og:site_name" content="Carl Thomé">
<meta property="og:title" content="tfcompile">
<meta property="og:url" content="https://carlthome.github.io/posts/tfcompile%20/">
<meta property="og:description" content="Example of how to use XLA AOT via tfcompile to build a Keras model into a shared library.">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2018-01-11T15:07:30Z">
<meta property="article:tag" content="keras model">
<meta property="article:tag" content="shared library">
<meta property="article:tag" content="use xla aot via tfcompile">
</head>
<body class="nav-closed">

<div class="nav">
    <h3 class="nav-title">Menu</h3>
    <a href="#" class="nav-close">
        <span class="hidden">Close</span>
    </a>
    <ul>
<li class="nav-opened" role="presentation">
            <a href="../../archive.html">Archive</a>
        </li>
        <li class="nav-opened" role="presentation">
            <a href="../../categories/">Tags</a>
        </li>
        <li class="nav-opened" role="presentation">
            <a href="../../rss.xml">RSS feed</a>
        </li>
    
    
    </ul>
</div>
<span class="nav-cover"></span>

<div class="site-wrapper">
    <header class="main-header post-head no-cover"><nav class="main-nav overlay clearfix"><a class="blog-logo" href="https://carlthome.github.io/"><img src="https://s.gravatar.com/avatar/174f3e24db14e65f532ce260643074c2?s=80" alt="Blog Logo"></a>
            <a class="menu-button" href="#"><span class="burger">☰</span><span class="word">Menu</span></a>
        </nav></header><main id="content" class="content" role="main"><article class="post post"><div style="text-align: center">
        <a alt="Launch notebook in Binder" href="https://mybinder.org/v2/gist/carlthome/6ae8a570e21069c60708017e3f96c9fd/master"><img src="../../assets/img/binder.svg"></a>
        <a alt="See Gist stars" href="https://gist.github.com/carlthome/6ae8a570e21069c60708017e3f96c9fd/stargazers"><img height="20" src="../../assets/img/github.svg"></a>
    </div>
    <section class="post-content"><div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Deploying-a-TensorFlow-graph-via-XLA-AOT-compilation">Deploying a TensorFlow graph via XLA AOT compilation<a class="anchor-link" href="../tfcompile%20/#Deploying-a-TensorFlow-graph-via-XLA-AOT-compilation">¶</a>
</h2>
<p>Many machine learning models are deployed as cloud services where you can accommodate a full-blown runtime, but managing servers and requiring internet connectivity for your app is a hassle. Instead, you can use tfcompile (a XLA CLI tool) to compile a TensorFlow graph to executable machine code, and then deploy that as a microservice or native application.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="XLA">XLA<a class="anchor-link" href="../tfcompile%20/#XLA">¶</a>
</h2>
<p><a href="https://www.tensorflow.org/performance/xla/">XLA</a> is a compiler of TensorFlow graphs.</p>
<ul>
<li>TensorFlow's graph abstraction incurs overhead.</li>
<li>XLA combats this so we can afford typing high-level code without relying on the existence of custom ops kernels.</li>
<li>The compiler can be used for graph optimization during model training, but we'll focus on ahead-of-time (AOT) compilation for model deployment.</li>
<li>Implementation is still maturing. XLA was released march last year and there are several commits per day.</li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://2.bp.blogspot.com/-yhjY3pc6oow/WLRn2z4mPBI/AAAAAAAACcU/t_EAR6QMwQQkTBPftJQEonaB2DMbRXmXwCLcB/s640/Screen%2BShot%2B2017-02-27%2Bat%2B9.54.12%2BAM.png" alt="image.png"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://www.tensorflow.org/images/how-does-xla-work.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Steps-for-ahead-of-time-compiling-a-graph-with-XLA">Steps for ahead-of-time compiling a graph with XLA<a class="anchor-link" href="../tfcompile%20/#Steps-for-ahead-of-time-compiling-a-graph-with-XLA">¶</a>
</h2>
<p>We'll use the command-line tool tfcompile via Bazel.</p>
<ol>
<li>Configure the subgraph to compile.</li>
<li>Use the tf_library build macro to compile the subgraph.</li>
<li>Write code to invoke the subgraph.</li>
<li>Create the final binary.</li>
</ol>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-0:-Model">Step 0: Model<a class="anchor-link" href="../tfcompile%20/#Step-0:-Model">¶</a>
</h3>
<p>Before we start compiling a graph we need to build our graph. Let's keep it simple by just loading a pretrained image classifier.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># This cell can be safely removed and doesn't need to be run.</span>
<span class="o">%</span><span class="k">env</span> CUDA_VISIBLE_DEVICES=''
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>env: CUDA_VISIBLE_DEVICES=''
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">set_learning_phase</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">ResNet50</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="mi">80</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>________________________________________________________________________________
Layer (type)              Output Shape      Param #  Connected to               
================================================================================
input_1 (InputLayer)      (None, 224, 224,  0                                   
________________________________________________________________________________
conv1 (Conv2D)            (None, 112, 112,  9472     input_1[0][0]              
________________________________________________________________________________
bn_conv1 (BatchNormalizat (None, 112, 112,  256      conv1[0][0]                
________________________________________________________________________________
activation_1 (Activation) (None, 112, 112,  0        bn_conv1[0][0]             
________________________________________________________________________________
max_pooling2d_1 (MaxPooli (None, 55, 55, 64 0        activation_1[0][0]         
________________________________________________________________________________
res2a_branch2a (Conv2D)   (None, 55, 55, 64 4160     max_pooling2d_1[0][0]      
________________________________________________________________________________
bn2a_branch2a (BatchNorma (None, 55, 55, 64 256      res2a_branch2a[0][0]       
________________________________________________________________________________
activation_2 (Activation) (None, 55, 55, 64 0        bn2a_branch2a[0][0]        
________________________________________________________________________________
res2a_branch2b (Conv2D)   (None, 55, 55, 64 36928    activation_2[0][0]         
________________________________________________________________________________
bn2a_branch2b (BatchNorma (None, 55, 55, 64 256      res2a_branch2b[0][0]       
________________________________________________________________________________
activation_3 (Activation) (None, 55, 55, 64 0        bn2a_branch2b[0][0]        
________________________________________________________________________________
res2a_branch2c (Conv2D)   (None, 55, 55, 25 16640    activation_3[0][0]         
________________________________________________________________________________
res2a_branch1 (Conv2D)    (None, 55, 55, 25 16640    max_pooling2d_1[0][0]      
________________________________________________________________________________
bn2a_branch2c (BatchNorma (None, 55, 55, 25 1024     res2a_branch2c[0][0]       
________________________________________________________________________________
bn2a_branch1 (BatchNormal (None, 55, 55, 25 1024     res2a_branch1[0][0]        
________________________________________________________________________________
add_1 (Add)               (None, 55, 55, 25 0        bn2a_branch2c[0][0]        
                                                     bn2a_branch1[0][0]         
________________________________________________________________________________
activation_4 (Activation) (None, 55, 55, 25 0        add_1[0][0]                
________________________________________________________________________________
res2b_branch2a (Conv2D)   (None, 55, 55, 64 16448    activation_4[0][0]         
________________________________________________________________________________
bn2b_branch2a (BatchNorma (None, 55, 55, 64 256      res2b_branch2a[0][0]       
________________________________________________________________________________
activation_5 (Activation) (None, 55, 55, 64 0        bn2b_branch2a[0][0]        
________________________________________________________________________________
res2b_branch2b (Conv2D)   (None, 55, 55, 64 36928    activation_5[0][0]         
________________________________________________________________________________
bn2b_branch2b (BatchNorma (None, 55, 55, 64 256      res2b_branch2b[0][0]       
________________________________________________________________________________
activation_6 (Activation) (None, 55, 55, 64 0        bn2b_branch2b[0][0]        
________________________________________________________________________________
res2b_branch2c (Conv2D)   (None, 55, 55, 25 16640    activation_6[0][0]         
________________________________________________________________________________
bn2b_branch2c (BatchNorma (None, 55, 55, 25 1024     res2b_branch2c[0][0]       
________________________________________________________________________________
add_2 (Add)               (None, 55, 55, 25 0        bn2b_branch2c[0][0]        
                                                     activation_4[0][0]         
________________________________________________________________________________
activation_7 (Activation) (None, 55, 55, 25 0        add_2[0][0]                
________________________________________________________________________________
res2c_branch2a (Conv2D)   (None, 55, 55, 64 16448    activation_7[0][0]         
________________________________________________________________________________
bn2c_branch2a (BatchNorma (None, 55, 55, 64 256      res2c_branch2a[0][0]       
________________________________________________________________________________
activation_8 (Activation) (None, 55, 55, 64 0        bn2c_branch2a[0][0]        
________________________________________________________________________________
res2c_branch2b (Conv2D)   (None, 55, 55, 64 36928    activation_8[0][0]         
________________________________________________________________________________
bn2c_branch2b (BatchNorma (None, 55, 55, 64 256      res2c_branch2b[0][0]       
________________________________________________________________________________
activation_9 (Activation) (None, 55, 55, 64 0        bn2c_branch2b[0][0]        
________________________________________________________________________________
res2c_branch2c (Conv2D)   (None, 55, 55, 25 16640    activation_9[0][0]         
________________________________________________________________________________
bn2c_branch2c (BatchNorma (None, 55, 55, 25 1024     res2c_branch2c[0][0]       
________________________________________________________________________________
add_3 (Add)               (None, 55, 55, 25 0        bn2c_branch2c[0][0]        
                                                     activation_7[0][0]         
________________________________________________________________________________
activation_10 (Activation (None, 55, 55, 25 0        add_3[0][0]                
________________________________________________________________________________
res3a_branch2a (Conv2D)   (None, 28, 28, 12 32896    activation_10[0][0]        
________________________________________________________________________________
bn3a_branch2a (BatchNorma (None, 28, 28, 12 512      res3a_branch2a[0][0]       
________________________________________________________________________________
activation_11 (Activation (None, 28, 28, 12 0        bn3a_branch2a[0][0]        
________________________________________________________________________________
res3a_branch2b (Conv2D)   (None, 28, 28, 12 147584   activation_11[0][0]        
________________________________________________________________________________
bn3a_branch2b (BatchNorma (None, 28, 28, 12 512      res3a_branch2b[0][0]       
________________________________________________________________________________
activation_12 (Activation (None, 28, 28, 12 0        bn3a_branch2b[0][0]        
________________________________________________________________________________
res3a_branch2c (Conv2D)   (None, 28, 28, 51 66048    activation_12[0][0]        
________________________________________________________________________________
res3a_branch1 (Conv2D)    (None, 28, 28, 51 131584   activation_10[0][0]        
________________________________________________________________________________
bn3a_branch2c (BatchNorma (None, 28, 28, 51 2048     res3a_branch2c[0][0]       
________________________________________________________________________________
bn3a_branch1 (BatchNormal (None, 28, 28, 51 2048     res3a_branch1[0][0]        
________________________________________________________________________________
add_4 (Add)               (None, 28, 28, 51 0        bn3a_branch2c[0][0]        
                                                     bn3a_branch1[0][0]         
________________________________________________________________________________
activation_13 (Activation (None, 28, 28, 51 0        add_4[0][0]                
________________________________________________________________________________
res3b_branch2a (Conv2D)   (None, 28, 28, 12 65664    activation_13[0][0]        
________________________________________________________________________________
bn3b_branch2a (BatchNorma (None, 28, 28, 12 512      res3b_branch2a[0][0]       
________________________________________________________________________________
activation_14 (Activation (None, 28, 28, 12 0        bn3b_branch2a[0][0]        
________________________________________________________________________________
res3b_branch2b (Conv2D)   (None, 28, 28, 12 147584   activation_14[0][0]        
________________________________________________________________________________
bn3b_branch2b (BatchNorma (None, 28, 28, 12 512      res3b_branch2b[0][0]       
________________________________________________________________________________
activation_15 (Activation (None, 28, 28, 12 0        bn3b_branch2b[0][0]        
________________________________________________________________________________
res3b_branch2c (Conv2D)   (None, 28, 28, 51 66048    activation_15[0][0]        
________________________________________________________________________________
bn3b_branch2c (BatchNorma (None, 28, 28, 51 2048     res3b_branch2c[0][0]       
________________________________________________________________________________
add_5 (Add)               (None, 28, 28, 51 0        bn3b_branch2c[0][0]        
                                                     activation_13[0][0]        
________________________________________________________________________________
activation_16 (Activation (None, 28, 28, 51 0        add_5[0][0]                
________________________________________________________________________________
res3c_branch2a (Conv2D)   (None, 28, 28, 12 65664    activation_16[0][0]        
________________________________________________________________________________
bn3c_branch2a (BatchNorma (None, 28, 28, 12 512      res3c_branch2a[0][0]       
________________________________________________________________________________
activation_17 (Activation (None, 28, 28, 12 0        bn3c_branch2a[0][0]        
________________________________________________________________________________
res3c_branch2b (Conv2D)   (None, 28, 28, 12 147584   activation_17[0][0]        
________________________________________________________________________________
bn3c_branch2b (BatchNorma (None, 28, 28, 12 512      res3c_branch2b[0][0]       
________________________________________________________________________________
activation_18 (Activation (None, 28, 28, 12 0        bn3c_branch2b[0][0]        
________________________________________________________________________________
res3c_branch2c (Conv2D)   (None, 28, 28, 51 66048    activation_18[0][0]        
________________________________________________________________________________
bn3c_branch2c (BatchNorma (None, 28, 28, 51 2048     res3c_branch2c[0][0]       
________________________________________________________________________________
add_6 (Add)               (None, 28, 28, 51 0        bn3c_branch2c[0][0]        
                                                     activation_16[0][0]        
________________________________________________________________________________
activation_19 (Activation (None, 28, 28, 51 0        add_6[0][0]                
________________________________________________________________________________
res3d_branch2a (Conv2D)   (None, 28, 28, 12 65664    activation_19[0][0]        
________________________________________________________________________________
bn3d_branch2a (BatchNorma (None, 28, 28, 12 512      res3d_branch2a[0][0]       
________________________________________________________________________________
activation_20 (Activation (None, 28, 28, 12 0        bn3d_branch2a[0][0]        
________________________________________________________________________________
res3d_branch2b (Conv2D)   (None, 28, 28, 12 147584   activation_20[0][0]        
________________________________________________________________________________
bn3d_branch2b (BatchNorma (None, 28, 28, 12 512      res3d_branch2b[0][0]       
________________________________________________________________________________
activation_21 (Activation (None, 28, 28, 12 0        bn3d_branch2b[0][0]        
________________________________________________________________________________
res3d_branch2c (Conv2D)   (None, 28, 28, 51 66048    activation_21[0][0]        
________________________________________________________________________________
bn3d_branch2c (BatchNorma (None, 28, 28, 51 2048     res3d_branch2c[0][0]       
________________________________________________________________________________
add_7 (Add)               (None, 28, 28, 51 0        bn3d_branch2c[0][0]        
                                                     activation_19[0][0]        
________________________________________________________________________________
activation_22 (Activation (None, 28, 28, 51 0        add_7[0][0]                
________________________________________________________________________________
res4a_branch2a (Conv2D)   (None, 14, 14, 25 131328   activation_22[0][0]        
________________________________________________________________________________
bn4a_branch2a (BatchNorma (None, 14, 14, 25 1024     res4a_branch2a[0][0]       
________________________________________________________________________________
activation_23 (Activation (None, 14, 14, 25 0        bn4a_branch2a[0][0]        
________________________________________________________________________________
res4a_branch2b (Conv2D)   (None, 14, 14, 25 590080   activation_23[0][0]        
________________________________________________________________________________
bn4a_branch2b (BatchNorma (None, 14, 14, 25 1024     res4a_branch2b[0][0]       
________________________________________________________________________________
activation_24 (Activation (None, 14, 14, 25 0        bn4a_branch2b[0][0]        
________________________________________________________________________________
res4a_branch2c (Conv2D)   (None, 14, 14, 10 263168   activation_24[0][0]        
________________________________________________________________________________
res4a_branch1 (Conv2D)    (None, 14, 14, 10 525312   activation_22[0][0]        
________________________________________________________________________________
bn4a_branch2c (BatchNorma (None, 14, 14, 10 4096     res4a_branch2c[0][0]       
________________________________________________________________________________
bn4a_branch1 (BatchNormal (None, 14, 14, 10 4096     res4a_branch1[0][0]        
________________________________________________________________________________
add_8 (Add)               (None, 14, 14, 10 0        bn4a_branch2c[0][0]        
                                                     bn4a_branch1[0][0]         
________________________________________________________________________________
activation_25 (Activation (None, 14, 14, 10 0        add_8[0][0]                
________________________________________________________________________________
res4b_branch2a (Conv2D)   (None, 14, 14, 25 262400   activation_25[0][0]        
________________________________________________________________________________
bn4b_branch2a (BatchNorma (None, 14, 14, 25 1024     res4b_branch2a[0][0]       
________________________________________________________________________________
activation_26 (Activation (None, 14, 14, 25 0        bn4b_branch2a[0][0]        
________________________________________________________________________________
res4b_branch2b (Conv2D)   (None, 14, 14, 25 590080   activation_26[0][0]        
________________________________________________________________________________
bn4b_branch2b (BatchNorma (None, 14, 14, 25 1024     res4b_branch2b[0][0]       
________________________________________________________________________________
activation_27 (Activation (None, 14, 14, 25 0        bn4b_branch2b[0][0]        
________________________________________________________________________________
res4b_branch2c (Conv2D)   (None, 14, 14, 10 263168   activation_27[0][0]        
________________________________________________________________________________
bn4b_branch2c (BatchNorma (None, 14, 14, 10 4096     res4b_branch2c[0][0]       
________________________________________________________________________________
add_9 (Add)               (None, 14, 14, 10 0        bn4b_branch2c[0][0]        
                                                     activation_25[0][0]        
________________________________________________________________________________
activation_28 (Activation (None, 14, 14, 10 0        add_9[0][0]                
________________________________________________________________________________
res4c_branch2a (Conv2D)   (None, 14, 14, 25 262400   activation_28[0][0]        
________________________________________________________________________________
bn4c_branch2a (BatchNorma (None, 14, 14, 25 1024     res4c_branch2a[0][0]       
________________________________________________________________________________
activation_29 (Activation (None, 14, 14, 25 0        bn4c_branch2a[0][0]        
________________________________________________________________________________
res4c_branch2b (Conv2D)   (None, 14, 14, 25 590080   activation_29[0][0]        
________________________________________________________________________________
bn4c_branch2b (BatchNorma (None, 14, 14, 25 1024     res4c_branch2b[0][0]       
________________________________________________________________________________
activation_30 (Activation (None, 14, 14, 25 0        bn4c_branch2b[0][0]        
________________________________________________________________________________
res4c_branch2c (Conv2D)   (None, 14, 14, 10 263168   activation_30[0][0]        
________________________________________________________________________________
bn4c_branch2c (BatchNorma (None, 14, 14, 10 4096     res4c_branch2c[0][0]       
________________________________________________________________________________
add_10 (Add)              (None, 14, 14, 10 0        bn4c_branch2c[0][0]        
                                                     activation_28[0][0]        
________________________________________________________________________________
activation_31 (Activation (None, 14, 14, 10 0        add_10[0][0]               
________________________________________________________________________________
res4d_branch2a (Conv2D)   (None, 14, 14, 25 262400   activation_31[0][0]        
________________________________________________________________________________
bn4d_branch2a (BatchNorma (None, 14, 14, 25 1024     res4d_branch2a[0][0]       
________________________________________________________________________________
activation_32 (Activation (None, 14, 14, 25 0        bn4d_branch2a[0][0]        
________________________________________________________________________________
res4d_branch2b (Conv2D)   (None, 14, 14, 25 590080   activation_32[0][0]        
________________________________________________________________________________
bn4d_branch2b (BatchNorma (None, 14, 14, 25 1024     res4d_branch2b[0][0]       
________________________________________________________________________________
activation_33 (Activation (None, 14, 14, 25 0        bn4d_branch2b[0][0]        
________________________________________________________________________________
res4d_branch2c (Conv2D)   (None, 14, 14, 10 263168   activation_33[0][0]        
________________________________________________________________________________
bn4d_branch2c (BatchNorma (None, 14, 14, 10 4096     res4d_branch2c[0][0]       
________________________________________________________________________________
add_11 (Add)              (None, 14, 14, 10 0        bn4d_branch2c[0][0]        
                                                     activation_31[0][0]        
________________________________________________________________________________
activation_34 (Activation (None, 14, 14, 10 0        add_11[0][0]               
________________________________________________________________________________
res4e_branch2a (Conv2D)   (None, 14, 14, 25 262400   activation_34[0][0]        
________________________________________________________________________________
bn4e_branch2a (BatchNorma (None, 14, 14, 25 1024     res4e_branch2a[0][0]       
________________________________________________________________________________
activation_35 (Activation (None, 14, 14, 25 0        bn4e_branch2a[0][0]        
________________________________________________________________________________
res4e_branch2b (Conv2D)   (None, 14, 14, 25 590080   activation_35[0][0]        
________________________________________________________________________________
bn4e_branch2b (BatchNorma (None, 14, 14, 25 1024     res4e_branch2b[0][0]       
________________________________________________________________________________
activation_36 (Activation (None, 14, 14, 25 0        bn4e_branch2b[0][0]        
________________________________________________________________________________
res4e_branch2c (Conv2D)   (None, 14, 14, 10 263168   activation_36[0][0]        
________________________________________________________________________________
bn4e_branch2c (BatchNorma (None, 14, 14, 10 4096     res4e_branch2c[0][0]       
________________________________________________________________________________
add_12 (Add)              (None, 14, 14, 10 0        bn4e_branch2c[0][0]        
                                                     activation_34[0][0]        
________________________________________________________________________________
activation_37 (Activation (None, 14, 14, 10 0        add_12[0][0]               
________________________________________________________________________________
res4f_branch2a (Conv2D)   (None, 14, 14, 25 262400   activation_37[0][0]        
________________________________________________________________________________
bn4f_branch2a (BatchNorma (None, 14, 14, 25 1024     res4f_branch2a[0][0]       
________________________________________________________________________________
activation_38 (Activation (None, 14, 14, 25 0        bn4f_branch2a[0][0]        
________________________________________________________________________________
res4f_branch2b (Conv2D)   (None, 14, 14, 25 590080   activation_38[0][0]        
________________________________________________________________________________
bn4f_branch2b (BatchNorma (None, 14, 14, 25 1024     res4f_branch2b[0][0]       
________________________________________________________________________________
activation_39 (Activation (None, 14, 14, 25 0        bn4f_branch2b[0][0]        
________________________________________________________________________________
res4f_branch2c (Conv2D)   (None, 14, 14, 10 263168   activation_39[0][0]        
________________________________________________________________________________
bn4f_branch2c (BatchNorma (None, 14, 14, 10 4096     res4f_branch2c[0][0]       
________________________________________________________________________________
add_13 (Add)              (None, 14, 14, 10 0        bn4f_branch2c[0][0]        
                                                     activation_37[0][0]        
________________________________________________________________________________
activation_40 (Activation (None, 14, 14, 10 0        add_13[0][0]               
________________________________________________________________________________
res5a_branch2a (Conv2D)   (None, 7, 7, 512) 524800   activation_40[0][0]        
________________________________________________________________________________
bn5a_branch2a (BatchNorma (None, 7, 7, 512) 2048     res5a_branch2a[0][0]       
________________________________________________________________________________
activation_41 (Activation (None, 7, 7, 512) 0        bn5a_branch2a[0][0]        
________________________________________________________________________________
res5a_branch2b (Conv2D)   (None, 7, 7, 512) 2359808  activation_41[0][0]        
________________________________________________________________________________
bn5a_branch2b (BatchNorma (None, 7, 7, 512) 2048     res5a_branch2b[0][0]       
________________________________________________________________________________
activation_42 (Activation (None, 7, 7, 512) 0        bn5a_branch2b[0][0]        
________________________________________________________________________________
res5a_branch2c (Conv2D)   (None, 7, 7, 2048 1050624  activation_42[0][0]        
________________________________________________________________________________
res5a_branch1 (Conv2D)    (None, 7, 7, 2048 2099200  activation_40[0][0]        
________________________________________________________________________________
bn5a_branch2c (BatchNorma (None, 7, 7, 2048 8192     res5a_branch2c[0][0]       
________________________________________________________________________________
bn5a_branch1 (BatchNormal (None, 7, 7, 2048 8192     res5a_branch1[0][0]        
________________________________________________________________________________
add_14 (Add)              (None, 7, 7, 2048 0        bn5a_branch2c[0][0]        
                                                     bn5a_branch1[0][0]         
________________________________________________________________________________
activation_43 (Activation (None, 7, 7, 2048 0        add_14[0][0]               
________________________________________________________________________________
res5b_branch2a (Conv2D)   (None, 7, 7, 512) 1049088  activation_43[0][0]        
________________________________________________________________________________
bn5b_branch2a (BatchNorma (None, 7, 7, 512) 2048     res5b_branch2a[0][0]       
________________________________________________________________________________
activation_44 (Activation (None, 7, 7, 512) 0        bn5b_branch2a[0][0]        
________________________________________________________________________________
res5b_branch2b (Conv2D)   (None, 7, 7, 512) 2359808  activation_44[0][0]        
________________________________________________________________________________
bn5b_branch2b (BatchNorma (None, 7, 7, 512) 2048     res5b_branch2b[0][0]       
________________________________________________________________________________
activation_45 (Activation (None, 7, 7, 512) 0        bn5b_branch2b[0][0]        
________________________________________________________________________________
res5b_branch2c (Conv2D)   (None, 7, 7, 2048 1050624  activation_45[0][0]        
________________________________________________________________________________
bn5b_branch2c (BatchNorma (None, 7, 7, 2048 8192     res5b_branch2c[0][0]       
________________________________________________________________________________
add_15 (Add)              (None, 7, 7, 2048 0        bn5b_branch2c[0][0]        
                                                     activation_43[0][0]        
________________________________________________________________________________
activation_46 (Activation (None, 7, 7, 2048 0        add_15[0][0]               
________________________________________________________________________________
res5c_branch2a (Conv2D)   (None, 7, 7, 512) 1049088  activation_46[0][0]        
________________________________________________________________________________
bn5c_branch2a (BatchNorma (None, 7, 7, 512) 2048     res5c_branch2a[0][0]       
________________________________________________________________________________
activation_47 (Activation (None, 7, 7, 512) 0        bn5c_branch2a[0][0]        
________________________________________________________________________________
res5c_branch2b (Conv2D)   (None, 7, 7, 512) 2359808  activation_47[0][0]        
________________________________________________________________________________
bn5c_branch2b (BatchNorma (None, 7, 7, 512) 2048     res5c_branch2b[0][0]       
________________________________________________________________________________
activation_48 (Activation (None, 7, 7, 512) 0        bn5c_branch2b[0][0]        
________________________________________________________________________________
res5c_branch2c (Conv2D)   (None, 7, 7, 2048 1050624  activation_48[0][0]        
________________________________________________________________________________
bn5c_branch2c (BatchNorma (None, 7, 7, 2048 8192     res5c_branch2c[0][0]       
________________________________________________________________________________
add_16 (Add)              (None, 7, 7, 2048 0        bn5c_branch2c[0][0]        
                                                     activation_46[0][0]        
________________________________________________________________________________
activation_49 (Activation (None, 7, 7, 2048 0        add_16[0][0]               
________________________________________________________________________________
avg_pool (AveragePooling2 (None, 1, 1, 2048 0        activation_49[0][0]        
________________________________________________________________________________
flatten_1 (Flatten)       (None, 2048)      0        avg_pool[0][0]             
________________________________________________________________________________
fc1000 (Dense)            (None, 1000)      2049000  flatten_1[0][0]            
================================================================================
Total params: 25,636,712
Trainable params: 25,583,592
Non-trainable params: 53,120
________________________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-0.5:-Download-tfcompile">Step 0.5: Download tfcompile<a class="anchor-link" href="../tfcompile%20/#Step-0.5:-Download-tfcompile">¶</a>
</h3>
<p>XLA is still maturing and as of now we have to checkout the development release. System prerequisites are git, the build tool <a href="https://docs.bazel.build">Bazel</a> and the <a href="https://developers.google.com/protocol-buffers">Protocol Buffers</a> compiler. I'm also assuming we're running tf-nightly which can be installed via pip.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">rm</span> -rf /tmp/tensorflow
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">cd</span> /tmp
<span class="o">!</span>git clone --depth<span class="o">=</span><span class="m">1</span> --single-branch https://github.com/tensorflow/tensorflow
<span class="o">%</span><span class="k">cd</span> tensorflow
<span class="o">!</span>yes <span class="s2">""</span> <span class="p">|</span> ./configure
<span class="o">!</span>protoc tensorflow/compiler/tf2xla/tf2xla.proto --python_out<span class="o">=</span>.
<span class="o">!</span>cp tensorflow/compiler/tf2xla/tf2xla_pb2.py .
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>/tmp
Cloning into 'tensorflow'...
remote: Counting objects: 10580, done.
remote: Compressing objects: 100% (8825/8825), done.
remote: Total 10580 (delta 3329), reused 3594 (delta 1486), pack-reused 0
Receiving objects: 100% (10580/10580), 21.65 MiB | 4.71 MiB/s, done.
Resolving deltas: 100% (3329/3329), done.
/tmp/tensorflow
WARNING: Running Bazel server needs to be killed, because the startup options are different.
You have bazel 0.8.1 installed.
Please specify the location of python. [Default is /home/carl/anaconda3/bin/python]: 

Found possible Python library paths:
  /home/carl/anaconda3/lib/python3.6/site-packages
Please input the desired Python library path to use.  Default is [/home/carl/anaconda3/lib/python3.6/site-packages]
Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: jemalloc as malloc support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: Google Cloud Platform support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Hadoop File System support? [Y/n]: Hadoop File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: Amazon S3 File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with XLA JIT support? [y/N]: No XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with GDR support? [y/N]: No GDR support will be enabled for TensorFlow.

Do you wish to build TensorFlow with VERBS support? [y/N]: No VERBS support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow.

Do you wish to build TensorFlow with MPI support? [y/N]: No MPI support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option "--config=opt" is specified [Default is -march=native]: 

Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding "--config=&lt;&gt;" to your build command. See tools/bazel.rc for more details.
	--config=mkl         	# Build with MKL support.
	--config=monolithic  	# Config for mostly static monolithic build.
Configuration finished
yes: standard output: Broken pipe
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-1:-Configure-the-subgraph-to-compile.">Step 1: Configure the subgraph to compile.<a class="anchor-link" href="../tfcompile%20/#Step-1:-Configure-the-subgraph-to-compile.">¶</a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="List-feeds-and-fetches">List feeds and fetches<a class="anchor-link" href="../tfcompile%20/#List-feeds-and-fetches">¶</a>
</h4>
<p>tfcompile needs static input shapes so we have to pick a batch size for our image classifier.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tf2xla_pb2</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">tf2xla_pb2</span><span class="o">.</span><span class="n">Config</span><span class="p">()</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">inputs</span><span class="p">:</span>
    <span class="n">x</span><span class="o">.</span><span class="n">set_shape</span><span class="p">([</span><span class="n">batch_size</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="n">feed</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">feed</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
    <span class="n">feed</span><span class="o">.</span><span class="n">id</span><span class="o">.</span><span class="n">node_name</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span>
    <span class="n">feed</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">MergeFrom</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">as_proto</span><span class="p">())</span>

<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">outputs</span><span class="p">:</span>
    <span class="n">fetch</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">fetch</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
    <span class="n">fetch</span><span class="o">.</span><span class="n">id</span><span class="o">.</span><span class="n">node_name</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'graph.config.pbtxt'</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">config</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cat</span> <span class="n">graph</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pbtxt</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>feed {
  id {
    node_name: "input_1"
  }
  shape {
    dim {
      size: 1
    }
    dim {
      size: 224
    }
    dim {
      size: 224
    }
    dim {
      size: 3
    }
  }
}
fetch {
  id {
    node_name: "fc1000/Softmax"
  }
}
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Freeze-graph">Freeze graph<a class="anchor-link" href="../tfcompile%20/#Freeze-graph">¶</a>
</h4>
<p>The graph contains mutable nodes that have to be constants. It's possible to let tfcompile handle this for you (via <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py">freeze_graph.py</a>) by providing a weights checkpoint along with the graph definition, but as we already have everything loaded we'll make them into constants right away.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">session</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span>
<span class="n">output_node_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">outputs</span><span class="p">]</span>
<span class="n">graphdef</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">graph_util</span><span class="o">.</span><span class="n">convert_variables_to_constants</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">session</span><span class="o">.</span><span class="n">graph_def</span><span class="p">,</span> <span class="n">output_node_names</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">write_graph</span><span class="p">(</span><span class="n">graphdef</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">,</span> <span class="s1">'graph.pb'</span><span class="p">,</span> <span class="n">as_text</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:tensorflow:Froze 320 variables.
Converted 320 variables to const ops.
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[10]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>'./graph.pb'</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-2:-Use-the-tf_library-build-macro-to-compile-the-subgraph.">Step 2: Use the tf_library build macro to compile the subgraph.<a class="anchor-link" href="../tfcompile%20/#Step-2:-Use-the-tf_library-build-macro-to-compile-the-subgraph.">¶</a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">writefile</span> BUILD

load('@org_tensorflow//tensorflow/compiler/aot:tfcompile.bzl', 'tf_library')

tf_library(
    name = 'graph',
    config = 'graph.config.pbtxt',
    cpp_class = 'Graph',
    graph = 'graph.pb',
)
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Overwriting BUILD
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>bazel build --show_progress_rate_limit<span class="o">=</span><span class="m">600</span> @org_tensorflow//:graph
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>.......
<span class="ansi-green-fg">Loading:</span> 
<span class="ansi-green-fg">Loading:</span> 0 packages loaded
<span class="ansi-magenta-fg">WARNING: </span>/home/carl/.cache/bazel/_bazel_carl/e5cce820cc082410b4fcc604db349066/external/org_tensorflow/tensorflow/core/BUILD:1816:1: in includes attribute of cc_library rule @org_tensorflow//tensorflow/core:framework_headers_lib: '../../../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'external/org_tensorflow/tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /home/carl/.cache/bazel/_bazel_carl/e5cce820cc082410b4fcc604db349066/external/org_tensorflow/tensorflow/tensorflow.bzl:1143:30
<span class="ansi-green-fg">Analyzing:</span> target @org_tensorflow//:graph (68 packages loaded)
<span class="ansi-green-fg">INFO: </span>Analysed target @org_tensorflow//:graph (74 packages loaded).
<span class="ansi-green-fg">Building:</span> no action running
<span class="ansi-green-fg">INFO: </span>Found 1 target...
<span class="ansi-green-fg">Building:</span> no action running
<span class="ansi-green-fg">[0 / 6]</span> BazelWorkspaceStatusAction stable-status.txt
<span class="ansi-green-fg">INFO: </span>From Executing genrule @org_tensorflow//tensorflow/core:version_info_gen [for host]:
<span class="ansi-green-fg">[1,674 / 3,309]</span> @org_tensorflow//tensorflow/core:version_info_gen; 0s local
fatal: No names found, cannot describe anything.
<span class="ansi-green-fg">[1,674 / 3,309]</span> @org_tensorflow//tensorflow/core:version_info_gen; 0s local
<span class="ansi-green-fg">INFO: </span>From Executing genrule @org_tensorflow//:gen_graph:
<span class="ansi-green-fg">[3,332 / 3,336]</span> Executing genrule @org_tensorflow//:gen_graph; 47s local
2018-01-11 15:27:20.408071: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library
2018-01-11 15:27:20.514752: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
<span class="ansi-green-fg">[3,332 / 3,336]</span> Executing genrule @org_tensorflow//:gen_graph; 47s local
Target @org_tensorflow//:graph up-to-date:
<span class="ansi-green-fg">[3,336 / 3,336]</span> no action running
  bazel-bin/external/org_tensorflow/libgraph.a
<span class="ansi-green-fg">[3,336 / 3,336]</span> no action running
  bazel-bin/external/org_tensorflow/libgraph.pic.a
<span class="ansi-green-fg">[3,336 / 3,336]</span> no action running
  bazel-bin/external/org_tensorflow/libgraph.so
<span class="ansi-green-fg">[3,336 / 3,336]</span> no action running
<span class="ansi-green-fg">INFO: </span>Elapsed time: 57.837s, Critical Path: 50.33s
<span class="ansi-green-fg">[3,336 / 3,336]</span> no action running
<span class="ansi-green-fg">INFO:</span> Build completed successfully, 3 total actions
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cat</span> <span class="n">bazel</span><span class="o">-</span><span class="n">genfiles</span><span class="o">/</span><span class="n">graph</span><span class="o">.</span><span class="n">h</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>// Generated by tfcompile, the TensorFlow graph compiler.  DO NOT EDIT!
//
// This header was generated via ahead-of-time compilation of a TensorFlow
// graph.  An object file corresponding to this header was also generated.
// This header gives access to the functionality in that object file.
//
// clang-format off

#ifndef TFCOMPILE_GENERATED_____graph_H_  // NOLINT(build/header_guard)
#define TFCOMPILE_GENERATED_____graph_H_  // NOLINT(build/header_guard)


#include "tensorflow/compiler/tf2xla/xla_compiled_cpu_function.h"
#include "tensorflow/core/platform/types.h"

namespace Eigen { struct ThreadPoolDevice; }
namespace xla { class ExecutableRunOptions; }

// (Implementation detail) Entry point to the function in the object file.
extern "C" void ____graph(
    void* result, const xla::ExecutableRunOptions* run_options,
    const void** args, void** temps, tensorflow::int64* profile_counters);


// Graph represents a computation previously specified in a
// TensorFlow graph, now compiled into executable code. This extends the generic
// XlaCompiledCpuFunction class with statically type-safe arg and result
// methods. Usage example:
//
//   Graph computation;
//   // ...set args using computation.argN methods
//   CHECK(computation.Run());
//   // ...inspect results using computation.resultN methods
//
// The Run method invokes the actual computation, with inputs read from arg
// buffers, and outputs written to result buffers. Each Run call may also use
// a set of temporary buffers for the computation.
//
// By default each instance of this class manages its own arg, result and temp
// buffers. The AllocMode constructor parameter may be used to modify the
// buffer allocation strategy.
//
// Under the default allocation strategy, this class is thread-compatible:
// o Calls to non-const methods require exclusive access to the object.
// o Concurrent calls to const methods are OK, if those calls are made while it
//   is guaranteed that no thread may call a non-const method.
//
// The logical function signature is:
//   (arg0: f32[1,224,224,3]) -&gt; (f32[1,1000])
//
// Memory stats:
//   arg bytes total:    602112
//   arg bytes aligned:  602112
//   temp bytes total:   17815208
//   temp bytes aligned: 17815232
class Graph : public tensorflow::XlaCompiledCpuFunction {
 public:
  // Number of input arguments for the compiled computation.
  static constexpr size_t kNumArgs = 1;

  // Byte size of each argument buffer. There are kNumArgs entries.
  static const intptr_t* ArgSizes() {
    static constexpr intptr_t kArgSizes[kNumArgs] = {602112};
    return kArgSizes;
  }

  // Returns static data used to create an XlaCompiledCpuFunction.
  static const tensorflow::XlaCompiledCpuFunction::StaticData&amp; StaticData() {
    static XlaCompiledCpuFunction::StaticData* kStaticData = [](){
      XlaCompiledCpuFunction::StaticData* data =
        new XlaCompiledCpuFunction::StaticData;
      data-&gt;raw_function = ____graph;
      data-&gt;arg_sizes = ArgSizes();
      data-&gt;num_args = kNumArgs;
      data-&gt;temp_sizes = TempSizes();
      data-&gt;num_temps = kNumTemps;
      data-&gt;result_index = kResultIndex;
      data-&gt;arg_names = StaticArgNames();
      data-&gt;result_names = StaticResultNames();
      data-&gt;program_shape = StaticProgramShape();
      return data;
    }();
    return *kStaticData;
  }

  Graph(AllocMode alloc_mode = AllocMode::ARGS_RESULTS_PROFILES_AND_TEMPS)
      : XlaCompiledCpuFunction(StaticData(), alloc_mode) {}

  Graph(const Graph&amp;) = delete;
  Graph&amp; operator=(const Graph&amp;) = delete;

  // Arg methods for managing input buffers. Buffers are in row-major order.
  // There is a set of methods for each positional argument, with the following
  // general form:
  //
  // void set_argN_data(void* data)
  //   Sets the buffer of type T for positional argument N. May be called in
  //   any AllocMode. Must be called before Run to have an affect. Must be
  //   called in AllocMode::RESULTS_PROFILES_AND_TEMPS_ONLY for each positional
  //   argument, to set the argument buffers.
  //
  // T* argN_data()
  //   Returns the buffer of type T for positional argument N.
  //
  // T&amp; argN(...dim indices...)
  //   Returns a reference to the value of type T for positional argument N,
  //   with dim indices specifying which value. No bounds checking is performed
  //   on dim indices.

  void set_arg0_data(void* data) {
    set_arg_data(0, data);
  }
  float* arg0_data() {
    return static_cast&lt;float*&gt;(arg_data(0));
  }
  float&amp; arg0(size_t dim0, size_t dim1, size_t dim2, size_t dim3) {
    return (*static_cast&lt;float(*)[1][224][224][3]&gt;(
        arg_data(0)))[dim0][dim1][dim2][dim3];
  }
  const float* arg0_data() const {
    return static_cast&lt;const float*&gt;(arg_data(0));
  }
  const float&amp; arg0(size_t dim0, size_t dim1, size_t dim2, size_t dim3) const {
    return (*static_cast&lt;const float(*)[1][224][224][3]&gt;(
        arg_data(0)))[dim0][dim1][dim2][dim3];
  }

  // Result methods for managing output buffers. Buffers are in row-major order.
  // Must only be called after a successful Run call. There is a set of methods
  // for each positional result, with the following general form:
  //
  // T* resultN_data()
  //   Returns the buffer of type T for positional result N.
  //
  // T&amp; resultN(...dim indices...)
  //   Returns a reference to the value of type T for positional result N,
  //   with dim indices specifying which value. No bounds checking is performed
  //   on dim indices.
  //
  // Unlike the arg methods, there is no set_resultN_data method. The result
  // buffers are managed internally, and may change after each call to Run.

  float* result0_data() {
    return static_cast&lt;float*&gt;(result_data(0));
  }
  float&amp; result0(size_t dim0, size_t dim1) {
    return (*static_cast&lt;float(*)[1][1000]&gt;(
        result_data(0)))[dim0][dim1];
  }
  const float* result0_data() const {
    return static_cast&lt;const float*&gt;(result_data(0));
  }
  const float&amp; result0(size_t dim0, size_t dim1) const {
    return (*static_cast&lt;const float(*)[1][1000]&gt;(
        result_data(0)))[dim0][dim1];
  }

 private:
  // Number of result and temporary buffers for the compiled computation.
  static constexpr size_t kNumTemps = 10;
  // The 0-based index of the result tuple in the temporary buffers.
  static constexpr size_t kResultIndex = 2;

  // Byte size of each result / temporary buffer. There are kNumTemps entries.
  static const intptr_t* TempSizes() {
    static constexpr intptr_t kTempSizes[kNumTemps] = {-1, 4000, 8, -1, -1, -1, -1, -1, -1, 17811200};
    return kTempSizes;
  }

  // Array of names of each positional argument, terminated by nullptr.
  static const char** StaticArgNames() {
    return nullptr;
  }

  // Array of names of each positional result, terminated by nullptr.
  static const char** StaticResultNames() {
    return nullptr;
  }

  // Shape of the args and results.
  static const xla::ProgramShape* StaticProgramShape() {
    return nullptr;
  }
};


#endif  // TFCOMPILE_GENERATED_____graph_H_

// clang-format on
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-3:-Write-code-to-invoke-the-subgraph.">Step 3: Write code to invoke the subgraph.<a class="anchor-link" href="../tfcompile%20/#Step-3:-Write-code-to-invoke-the-subgraph.">¶</a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">writefile</span> graph.cc

#define EIGEN_USE_THREADS
#define EIGEN_USE_CUSTOM_THREAD_POOL

#include "graph.h"
#include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"

extern "C" int run(float *input, float *output, int input_size, int output_size) {
  Eigen::ThreadPool tp(std::thread::hardware_concurrency());
  Eigen::ThreadPoolDevice device(&amp;tp, tp.NumThreads());
  Graph graph;
  graph.set_thread_pool(&amp;device);

  std::copy(input, input + input_size, graph.arg0_data());
  auto ok = graph.Run();
  if (not ok) return -1;
  std::copy(graph.result0_data(), graph.result0_data() + output_size, output);
  return 0;
}
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Writing graph.cc
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-4:-Create-the-final-binary.">Step 4: Create the final binary.<a class="anchor-link" href="../tfcompile%20/#Step-4:-Create-the-final-binary.">¶</a>
</h3>
<p>Instead of calling <code>gcc</code> directly, and as Bazel is already required for building the tfcompile tool, we'll make a <code>cc_binary</code> rule. In fact, we could just have done one big BUILD file directly after having cloned the TensorFlow repo.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">writefile</span> -a BUILD

cc_binary(
    name = "libmodel.so",
    srcs = ["graph.cc"],
    deps = [":graph", "//third_party/eigen3"],
    linkopts = ["-lpthread"],
    linkshared = 1,
    copts = ["-fPIC"],
)
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Appending to BUILD
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>bazel build --show_progress_rate_limit<span class="o">=</span><span class="m">60</span> @org_tensorflow//:libmodel.so
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-green-fg">Loading:</span> 
<span class="ansi-green-fg">Loading:</span> 0 packages loaded
<span class="ansi-magenta-fg">WARNING: </span>/home/carl/.cache/bazel/_bazel_carl/e5cce820cc082410b4fcc604db349066/external/org_tensorflow/tensorflow/core/BUILD:1816:1: in includes attribute of cc_library rule @org_tensorflow//tensorflow/core:framework_headers_lib: '../../../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'external/org_tensorflow/tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /home/carl/.cache/bazel/_bazel_carl/e5cce820cc082410b4fcc604db349066/external/org_tensorflow/tensorflow/tensorflow.bzl:1143:30
<span class="ansi-green-fg">Analyzing:</span> target @org_tensorflow//:libmodel.so (2 packages loaded)
<span class="ansi-green-fg">INFO: </span>Analysed target @org_tensorflow//:libmodel.so (2 packages loaded).
<span class="ansi-green-fg">Building:</span> no action running
<span class="ansi-green-fg">INFO: </span>Found 1 target...
<span class="ansi-green-fg">Building:</span> no action running
<span class="ansi-green-fg">[0 / 5]</span> BazelWorkspaceStatusAction stable-status.txt
Target @org_tensorflow//:libmodel.so up-to-date:
<span class="ansi-green-fg">[632 / 632]</span> no action running
  bazel-bin/external/org_tensorflow/libmodel.so
<span class="ansi-green-fg">[632 / 632]</span> no action running
<span class="ansi-green-fg">INFO: </span>Elapsed time: 1.852s, Critical Path: 0.56s
<span class="ansi-green-fg">[632 / 632]</span> no action running
<span class="ansi-green-fg">INFO:</span> Build completed successfully, 1 total action
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">libmodel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ctypeslib</span><span class="o">.</span><span class="n">load_library</span><span class="p">(</span><span class="s1">'libmodel'</span><span class="p">,</span> <span class="s1">'bazel-bin/external/org_tensorflow'</span><span class="p">)</span>
<span class="n">libmodel</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">argtypes</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ctypeslib</span><span class="o">.</span><span class="n">ndpointer</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">flags</span><span class="o">=</span><span class="p">(</span><span class="s1">'c'</span><span class="p">,</span> <span class="s1">'a'</span><span class="p">)),</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ctypeslib</span><span class="o">.</span><span class="n">ndpointer</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">),</span> <span class="n">flags</span><span class="o">=</span><span class="p">(</span><span class="s1">'c'</span><span class="p">,</span> <span class="s1">'a'</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">)),</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ctypeslib</span><span class="o">.</span><span class="n">ctypes</span><span class="o">.</span><span class="n">c_int</span><span class="p">,</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ctypeslib</span><span class="o">.</span><span class="n">ctypes</span><span class="o">.</span><span class="n">c_int</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">require</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">(</span><span class="s1">'c'</span><span class="p">,</span> <span class="s1">'a'</span><span class="p">))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">require</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">(</span><span class="s1">'c'</span><span class="p">,</span> <span class="s1">'a'</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">))</span>
    <span class="n">libmodel</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.preprocessing</span> <span class="k">import</span> <span class="n">image</span>
<span class="kn">from</span> <span class="nn">keras.applications.imagenet_utils</span> <span class="k">import</span> <span class="n">preprocess_input</span><span class="p">,</span> <span class="n">decode_predictions</span>

<span class="n">image_path</span> <span class="o">=</span> <span class="nb">input</span><span class="p">()</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">load_img</span><span class="p">(</span><span class="n">image_path</span><span class="p">,</span> <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">preprocess_input</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">decode_predictions</span><span class="p">(</span><span class="n">y</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[20]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[('n02110806', 'basenji', 0.60816735),
 ('n02441942', 'weasel', 0.10849755),
 ('n02091244', 'Ibizan_hound', 0.081580825),
 ('n02124075', 'Egyptian_cat', 0.044705715),
 ('n02123597', 'Siamese_cat', 0.025189402)]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [36]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">timeit</span> model.predict(x)
<span class="o">%</span><span class="k">timeit</span> predict(x)
<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>150 ms ± 199 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)
191 ms ± 604 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [37]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">timeit</span>
model = tf.keras.applications.ResNet50()
model.predict(x)
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>2.96 s ± 456 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="References">References<a class="anchor-link" href="../tfcompile%20/#References">¶</a>
</h2>
<ul>
<li><a href="https://www.tensorflow.org/performance/xla/tfcompile">https://www.tensorflow.org/performance/xla/tfcompile</a></li>
<li><a href="https://developers.googleblog.com/2017/03/xla-tensorflow-compiled.html">https://developers.googleblog.com/2017/03/xla-tensorflow-compiled.html</a></li>
<li><a href="https://youtu.be/kAOanJczHA0">https://youtu.be/kAOanJczHA0</a></li>
<li><a href="https://youtu.be/2IOPpyyuLkc">https://youtu.be/2IOPpyyuLkc</a></li>
</ul>
</div>
</div>
</div>
</div>
    </section><footer class="post-footer"><section class="comments hidden-print"><h2>Comments</h2>
        
        
        <div id="disqus_thread"></div>
        <script>
        var disqus_shortname ="carlthome",
            disqus_url="https://carlthome.github.io/posts/tfcompile%20/",
        disqus_title="tfcompile",
        disqus_identifier="cache/posts/tfcompile.html",
        disqus_config = function () {
            this.language = "en";
        };
        (function() {
            var dsq = document.createElement('script'); dsq.async = true;
            dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a>
</noscript>
    <a href="https://disqus.com" class="dsq-brlink" rel="nofollow">Comments powered by <span class="logo-disqus">Disqus</span></a>


        </section><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha256-SDRP1VVYu+tgAGKhddBSl5+ezofHKZeI+OzxakbIe/Y=" crossorigin="anonymous"></script><script type="text/x-mathjax-config">
        MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']]}});
        </script></footer></article><script>var disqus_shortname="carlthome";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script></main><footer class="site-footer clearfix"><section class="poweredby">CC BY-SA 2018 <a href="mailto:carlthome@gmail.com">Carl Thomé</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></section></footer>
</div>

    <script type="text/javascript" src="../../assets/js/jquery.js"></script><script type="text/javascript" src="../../assets/js/jquery.fitvids.js"></script><script type="text/javascript" src="../../assets/js/index.js"></script>
</body>
</html>
